{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaXxlTt_8Oyw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To dynamically adjust the region of interest (ROI) based on detected lanes from previous frames"
      ],
      "metadata": {
        "id": "3Btbv98Y8ffC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Gaussian blur kernel size\n",
        "BLUR_KERNEL_SIZE = 5\n",
        "\n",
        "# Preprocessing with improved noise reduction\n",
        "def preprocess(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Detect white lanes\n",
        "    white_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    # Detect yellow lanes\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Combine masks\n",
        "    combined_mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "\n",
        "    # Reduce noise with Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(combined_mask, (BLUR_KERNEL_SIZE, BLUR_KERNEL_SIZE), 0)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "# Define region of interest (ROI) dynamically\n",
        "def region_of_interest(img, vertices):\n",
        "    mask = np.zeros_like(img)\n",
        "    cv2.fillPoly(mask, [np.array(vertices, np.int32)], 255)\n",
        "    return cv2.bitwise_and(img, mask)\n",
        "\n",
        "# Fit lines using weighted averages (exponential moving average)\n",
        "def smooth_line_fit(history, new_fit, alpha=0.2):\n",
        "    if new_fit is None:\n",
        "        return history[-1] if history else None\n",
        "    if history:\n",
        "        return alpha * new_fit + (1 - alpha) * history[-1]\n",
        "    return new_fit\n",
        "\n",
        "# Draw lane lines with improved fitting\n",
        "def draw_lane_lines(frame, edges, left_fit_history, right_fit_history, history_size=5):\n",
        "    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi / 180, threshold=50, minLineLength=50, maxLineGap=150)\n",
        "\n",
        "    left_fit = []\n",
        "    right_fit = []\n",
        "\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            if x2 == x1:  # Skip vertical lines\n",
        "                continue\n",
        "            slope = (y2 - y1) / (x2 - x1)\n",
        "            intercept = y1 - slope * x1\n",
        "\n",
        "            # Classify lines into left or right based on slope\n",
        "            if slope < -0.5:  # Left lane\n",
        "                left_fit.append((slope, intercept))\n",
        "            elif slope > 0.5:  # Right lane\n",
        "                right_fit.append((slope, intercept))\n",
        "\n",
        "    # Average current frame's line fits\n",
        "    left_fit_avg = np.mean(left_fit, axis=0) if left_fit else None\n",
        "    right_fit_avg = np.mean(right_fit, axis=0) if right_fit else None\n",
        "\n",
        "    # Smooth fits using weighted average\n",
        "    left_fit_smooth = smooth_line_fit(left_fit_history, left_fit_avg)\n",
        "    right_fit_smooth = smooth_line_fit(right_fit_history, right_fit_avg)\n",
        "\n",
        "    # Update history\n",
        "    if left_fit_smooth is not None:\n",
        "        left_fit_history.append(left_fit_smooth)\n",
        "        if len(left_fit_history) > history_size:\n",
        "            left_fit_history.pop(0)\n",
        "\n",
        "    if right_fit_smooth is not None:\n",
        "        right_fit_history.append(right_fit_smooth)\n",
        "        if len(right_fit_history) > history_size:\n",
        "            right_fit_history.pop(0)\n",
        "\n",
        "    # Draw the lane lines\n",
        "    if left_fit_smooth is not None:\n",
        "        frame = extend_and_draw_line(frame, left_fit_smooth, color=(255, 0, 0))  # Left lane in blue\n",
        "    if right_fit_smooth is not None:\n",
        "        frame = extend_and_draw_line(frame, right_fit_smooth, color=(0, 255, 0))  # Right lane in green\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Helper function to extend and draw lines\n",
        "def extend_and_draw_line(frame, line_fit, color=(0, 255, 0), thickness=4):\n",
        "    slope, intercept = line_fit\n",
        "    height, width, _ = frame.shape\n",
        "    y1 = height  # Bottom of the image\n",
        "    y2 = int(height * 0.6)  # A little below the middle of the image\n",
        "    # Calculate corresponding x-coordinates\n",
        "    x1 = int((y1 - intercept) / slope)\n",
        "    x2 = int((y2 - intercept) / slope)\n",
        "    # Draw the line\n",
        "    cv2.line(frame, (x1, y1), (x2, y2), color, thickness)\n",
        "    return frame\n",
        "\n",
        "# Main function for processing video\n",
        "def main():\n",
        "    video_input_path = '/content/challenge_video.mp4'  # Path to input video\n",
        "    video_output_path = 'output_video.avi'  # Path to save processed video\n",
        "\n",
        "    video = cv2.VideoCapture(video_input_path)\n",
        "    if not video.isOpened():\n",
        "        print(\"Error: Unable to access video.\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define codec and create VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(video_output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Initialize line fit histories\n",
        "    left_fit_history = []\n",
        "    right_fit_history = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            print(\"End of video stream.\")\n",
        "            break\n",
        "\n",
        "        # Preprocess the frame\n",
        "        processed = preprocess(frame)\n",
        "\n",
        "        # Define the region of interest (ROI)\n",
        "        roi_vertices = [\n",
        "            (int(0.1 * width), height),\n",
        "            (int(0.4 * width), int(height * 0.6)),\n",
        "            (int(0.6 * width), int(height * 0.6)),\n",
        "            (int(0.9 * width), height)\n",
        "        ]\n",
        "        roi = region_of_interest(processed, roi_vertices)\n",
        "\n",
        "        # Detect edges\n",
        "        edges = cv2.Canny(roi, 50, 150)\n",
        "\n",
        "        # Draw lane lines\n",
        "        output_frame = draw_lane_lines(frame, edges, left_fit_history, right_fit_history)\n",
        "\n",
        "        # Save the output frame\n",
        "        out.write(output_frame)\n",
        "\n",
        "        # Display the frame in Colab\n",
        "        cv2_imshow(output_frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release resources\n",
        "    video.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "lRWKrK8m8TX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement multi-lane detection, we can use a clustering algorithm like DBSCAN to group detected lines into clusters corresponding to different lanes"
      ],
      "metadata": {
        "id": "wU2lgFir8mES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "from google.colab.patches import cv2_imshow  # Importing cv2_imshow for Colab\n",
        "\n",
        "# Gaussian blur kernel size\n",
        "BLUR_KERNEL_SIZE = 5\n",
        "\n",
        "def preprocess(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Detect white lanes\n",
        "    white_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    # Detect yellow lanes\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Combine masks\n",
        "    combined_mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "\n",
        "    # Reduce noise with Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(combined_mask, (BLUR_KERNEL_SIZE, BLUR_KERNEL_SIZE), 0)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "def region_of_interest(img, vertices):\n",
        "    mask = np.zeros_like(img)\n",
        "    cv2.fillPoly(mask, [np.array(vertices, np.int32)], 255)\n",
        "    return cv2.bitwise_and(img, mask)\n",
        "\n",
        "# Extend and draw detected lanes\n",
        "def extend_and_draw_line(frame, line_fit, color, thickness=4):\n",
        "    slope, intercept = line_fit\n",
        "    height, width, _ = frame.shape\n",
        "    y1 = height  # Bottom of the image\n",
        "    y2 = int(height * 0.6)  # A little below the middle of the image\n",
        "    x1 = int((y1 - intercept) / slope)\n",
        "    x2 = int((y2 - intercept) / slope)\n",
        "    cv2.line(frame, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "# Improved multi-lane detection\n",
        "def detect_and_draw_lanes(frame, edges, debug=False):\n",
        "    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi / 180, threshold=50, minLineLength=50, maxLineGap=150)\n",
        "    if lines is None:\n",
        "        return frame\n",
        "\n",
        "    # Extract line parameters (slope, intercept)\n",
        "    line_features = []\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "        if x2 == x1:  # Skip vertical lines\n",
        "            continue\n",
        "        slope = (y2 - y1) / (x2 - x1)\n",
        "        intercept = y1 - slope * x1\n",
        "        # Filter out near-horizontal lines\n",
        "        if abs(slope) < 0.3 or abs(slope) > 5:  # Adjust thresholds as needed\n",
        "            continue\n",
        "        line_features.append([slope, intercept])\n",
        "\n",
        "    if not line_features:\n",
        "        return frame\n",
        "\n",
        "    # Cluster lines using DBSCAN\n",
        "    line_features = np.array(line_features)\n",
        "    eps_value = 0.2  # DBSCAN distance threshold for clustering\n",
        "    clustering = DBSCAN(eps=eps_value, min_samples=2).fit(line_features)\n",
        "    labels = clustering.labels_\n",
        "\n",
        "    # Draw lanes for each cluster\n",
        "    unique_labels = set(labels)\n",
        "    for label in unique_labels:\n",
        "        if label == -1:  # Noise points\n",
        "            continue\n",
        "        cluster_lines = line_features[labels == label]\n",
        "        avg_slope, avg_intercept = np.mean(cluster_lines, axis=0)\n",
        "        extend_and_draw_line(frame, (avg_slope, avg_intercept), color=(0, 255, 0))  # Green for clustered lanes\n",
        "\n",
        "    # Debug visualization (optional)\n",
        "    if debug:\n",
        "        for line, label in zip(line_features, labels):\n",
        "            slope, intercept = line\n",
        "            color = (0, 255, 255) if label == -1 else (255, 0, 0)  # Yellow for noise, Blue for clusters\n",
        "            extend_and_draw_line(frame, (slope, intercept), color, thickness=2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Main function for video processing\n",
        "def main():\n",
        "    video_input_path = '/content/challenge_video.mp4'\n",
        "    video_output_path = 'output_video.avi'\n",
        "\n",
        "    video = cv2.VideoCapture(video_input_path)\n",
        "    if not video.isOpened():\n",
        "        print(\"Error: Unable to access video.\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define codec and create VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(video_output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            print(\"End of video stream.\")\n",
        "            break\n",
        "\n",
        "        # Preprocess the frame\n",
        "        processed = preprocess(frame)\n",
        "\n",
        "        # Define the region of interest (ROI)\n",
        "        roi_vertices = [\n",
        "            (int(0.1 * width), height),\n",
        "            (int(0.4 * width), int(height * 0.6)),\n",
        "            (int(0.6 * width), int(height * 0.6)),\n",
        "            (int(0.9 * width), height)\n",
        "        ]\n",
        "        roi = region_of_interest(processed, roi_vertices)\n",
        "\n",
        "        # Detect edges\n",
        "        edges = cv2.Canny(roi, 50, 150)\n",
        "\n",
        "        # Detect and draw lanes\n",
        "        output_frame = detect_and_draw_lanes(frame, edges, debug=True)\n",
        "\n",
        "        # Save and display the output frame\n",
        "        out.write(output_frame)\n",
        "        cv2_imshow(output_frame)  # Use cv2_imshow for Colab\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release resources\n",
        "    video.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "IEa9Zwkv8ngt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}